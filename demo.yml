# The configurations that used for the recording, feel free to edit them
config:

  # Specify a command to be executed
  # like `/bin/bash -l`, `ls`, or any other commands
  # the default is bash for Linux
  # or powershell.exe for Windows
  command: bash -l

  # Specify the current working directory path
  # the default is the current working directory path
  cwd: .

  # Export additional ENV variables
  env:
    recording: true

  # Explicitly set the number of columns
  # or use `auto` to take the current
  # number of columns of your shell
  cols: 150

  # Explicitly set the number of rows
  # or use `auto` to take the current
  # number of rows of your shell
  rows: 50

  # Amount of times to repeat GIF
  # If value is -1, play once
  # If value is 0, loop indefinitely
  # If value is a positive number, loop n times
  repeat: 0

  # Quality
  # 1 - 100
  quality: 100

  # Delay between frames in ms
  # If the value is `auto` use the actual recording delays
  frameDelay: auto

  # Maximum delay between frames in ms
  # Ignored if the `frameDelay` isn't set to `auto`
  # Set to `auto` to prevent limiting the max idle time
  maxIdleTime: 10000

  # The surrounding frame box
  # The `type` can be null, window, floating, or solid`
  # To hide the title use the value null
  # Don't forget to add a backgroundColor style with a null as type
  frameBox:
    type: floating
    title: onnx2tf demo
    style:
      border: 0px black solid
      # boxShadow: none
      # margin: 0px

  # Add a watermark image to the rendered gif
  # You need to specify an absolute path for
  # the image on your machine or a URL, and you can also
  # add your own CSS styles
  watermark:
    imagePath: null
    style:
      position: absolute
      right: 15px
      bottom: 15px
      width: 100px
      opacity: 0.9

  # Cursor style can be one of
  # `block`, `underline`, or `bar`
  cursorStyle: block

  # Font family
  # You can use any font that is installed on your machine
  # in CSS-like syntax
  fontFamily: "Monaco, Lucida Console, Ubuntu Mono, Monospace"

  # The size of the font
  fontSize: 18

  # The height of lines
  lineHeight: 1

  # The spacing between letters
  letterSpacing: 0

  # Theme
  theme:
    background: "#000000" #"transparent"
    foreground: "#afafaf"
    cursor: "#c7c7c7"
    black: "#232628"
    red: "#fc4384"
    green: "#b3e33b"
    yellow: "#ffa727"
    blue: "#75dff2"
    magenta: "#ae89fe"
    cyan: "#708387"
    white: "#d5d5d0"
    brightBlack: "#626566"
    brightRed: "#ff7fac"
    brightGreen: "#c8ed71"
    brightYellow: "#ebdf86"
    brightBlue: "#75dff2"
    brightMagenta: "#ae89fe"
    brightCyan: "#b1c6ca"
    brightWhite: "#f9f9f4"

# Records, feel free to edit them
records:
  - delay: 150
    content: "\e]0;xxxxxxx@xxxxxxx:~/git/onnx2tf\e\\\e]7;file://xxxxxxx/home/xxxxxxx/git/onnx2tf\e\\\e]0;xxxxxxx@xxxxxxx: ~/git/onnx2tf\a\e[01;32m\e[01;34m~/git/onnx2tf\e[00m$ "
  - delay: 150
    content: o
  - delay: 150
    content: 'n'
  - delay: 150
    content: 'n'
  - delay: 150
    content: x
  - delay: 150
    content: '2'
  - delay: 150
    content: t
  - delay: 150
    content: f
  - delay: 150
    content: ' '
  - delay: 150
    content: '-'
  - delay: 150
    content: i
  - delay: 150
    content: ' '
  - delay: 150
    content: r
  - delay: 150
    content: e
  - delay: 150
    content: "\a"
  - delay: 150
    content: s
  - delay: 150
    content: 'net18-v1-7.onnx '
  - delay: 4000
    content: "\r\n"
  - delay: 1778
    content: "\r\n\e[07mModel loaded\e[0m ========================================================================\r\n\r\n\e[07mModel convertion started\e[0m ============================================================\r\n\e[32mINFO:\e[0m \e[32minput_op_name\e[0m: data \e[32mshape\e[0m: ['N', 3, 224, 224] \e[32mdtype\e[0m: float32\r\n"
  - delay: 200
    content: "\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Conv \e[33monnx_op_name\e[0m: resnetv15_conv0_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: data \e[34mshape\e[0m: ['N', 3, 224, 224] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: 174 \e[34mshape\e[0m: [64, 3, 7, 7] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34minput_name.3\e[0m: 176 \e[34mshape\e[0m: [64] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_conv0_fwd \e[34mshape\e[0m: ['N', 64, 112, 112] \e[34mdtype\e[0m: float32\r\n"
  - delay: 200
    content: "\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Conv \e[36moutput_name.0\e[0m: resnetv15_conv0_fwd \e[36mshape\e[0m: (None, 112, 112, 64) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Relu \e[33monnx_op_name\e[0m: resnetv15_relu0_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_conv0_fwd \e[34mshape\e[0m: ['N', 64, 112, 112] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_relu0_fwd \e[34mshape\e[0m: ['N', 64, 112, 112] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Relu \e[36moutput_name.0\e[0m: resnetv15_relu0_fwd \e[36mshape\e[0m: (None, 112, 112, 64) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: MaxPool \e[33monnx_op_name\e[0m: resnetv15_pool0_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_relu0_fwd \e[34mshape\e[0m: ['N', 64, 112, 112] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_pool0_fwd \e[34mshape\e[0m: ['N', 64, 56, 56] \e[34mdtype\e[0m: float32\r\n"
  - delay: 200
    content: "\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: MaxPool \e[36moutput_name.0\e[0m: resnetv15_pool0_fwd \e[36mshape\e[0m: (None, 55, 55, 64) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Conv \e[33monnx_op_name\e[0m: resnetv15_stage1_conv0_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_pool0_fwd \e[34mshape\e[0m: ['N', 64, 56, 56] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: 178 \e[34mshape\e[0m: [64, 64, 3, 3] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34minput_name.3\e[0m: 180 \e[34mshape\e[0m: [64] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage1_conv0_fwd \e[34mshape\e[0m: ['N', 64, 56, 56] \e[34mdtype\e[0m: float32\r\n"
  - delay: 200
    content: "\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Conv \e[36moutput_name.0\e[0m: resnetv15_stage1_conv0_fwd \e[36mshape\e[0m: (None, 55, 55, 64) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Relu \e[33monnx_op_name\e[0m: resnetv15_stage1_relu0_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage1_conv0_fwd \e[34mshape\e[0m: ['N', 64, 56, 56] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage1_relu0_fwd \e[34mshape\e[0m: ['N', 64, 56, 56] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Relu \e[36moutput_name.0\e[0m: resnetv15_stage1_relu0_fwd \e[36mshape\e[0m: (None, 55, 55, 64) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Conv \e[33monnx_op_name\e[0m: resnetv15_stage1_conv1_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage1_relu0_fwd \e[34mshape\e[0m: ['N', 64, 56, 56] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: 182 \e[34mshape\e[0m: [64, 64, 3, 3] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34minput_name.3\e[0m: 184 \e[34mshape\e[0m: [64] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage1_conv1_fwd \e[34mshape\e[0m: ['N', 64, 56, 56] \e[34mdtype\e[0m: float32\r\n"
  - delay: 200
    content: "\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Conv \e[36moutput_name.0\e[0m: resnetv15_stage1_conv1_fwd \e[36mshape\e[0m: (None, 55, 55, 64) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Add \e[33monnx_op_name\e[0m: resnetv15_stage1__plus0\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_pool0_fwd \e[34mshape\e[0m: ['N', 64, 56, 56] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: resnetv15_stage1_conv1_fwd \e[34mshape\e[0m: ['N', 64, 56, 56] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage1__plus0 \e[34mshape\e[0m: ['N', 64, 56, 56] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Add \e[36moutput_name.0\e[0m: resnetv15_stage1__plus0 \e[36mshape\e[0m: (None, 55, 55, 64) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Relu \e[33monnx_op_name\e[0m: resnetv15_stage1_activation0\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage1__plus0 \e[34mshape\e[0m: ['N', 64, 56, 56] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage1_activation0 \e[34mshape\e[0m: ['N', 64, 56, 56] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Relu \e[36moutput_name.0\e[0m: resnetv15_stage1_activation0 \e[36mshape\e[0m: (None, 55, 55, 64) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Conv \e[33monnx_op_name\e[0m: resnetv15_stage1_conv2_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage1_activation0 \e[34mshape\e[0m: ['N', 64, 56, 56] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: 186 \e[34mshape\e[0m: [64, 64, 3, 3] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34minput_name.3\e[0m: 188 \e[34mshape\e[0m: [64] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage1_conv2_fwd \e[34mshape\e[0m: ['N', 64, 56, 56] \e[34mdtype\e[0m: float32\r\n"
  - delay: 200
    content: "\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Conv \e[36moutput_name.0\e[0m: resnetv15_stage1_conv2_fwd \e[36mshape\e[0m: (None, 55, 55, 64) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Relu \e[33monnx_op_name\e[0m: resnetv15_stage1_relu1_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage1_conv2_fwd \e[34mshape\e[0m: ['N', 64, 56, 56] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage1_relu1_fwd \e[34mshape\e[0m: ['N', 64, 56, 56] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Relu \e[36moutput_name.0\e[0m: resnetv15_stage1_relu1_fwd \e[36mshape\e[0m: (None, 55, 55, 64) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Conv \e[33monnx_op_name\e[0m: resnetv15_stage1_conv3_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage1_relu1_fwd \e[34mshape\e[0m: ['N', 64, 56, 56] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: 190 \e[34mshape\e[0m: [64, 64, 3, 3] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34minput_name.3\e[0m: 192 \e[34mshape\e[0m: [64] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage1_conv3_fwd \e[34mshape\e[0m: ['N', 64, 56, 56] \e[34mdtype\e[0m: float32\r\n"
  - delay: 200
    content: "\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Conv \e[36moutput_name.0\e[0m: resnetv15_stage1_conv3_fwd \e[36mshape\e[0m: (None, 55, 55, 64) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Add \e[33monnx_op_name\e[0m: resnetv15_stage1__plus1\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage1_activation0 \e[34mshape\e[0m: ['N', 64, 56, 56] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: resnetv15_stage1_conv3_fwd \e[34mshape\e[0m: ['N', 64, 56, 56] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage1__plus1 \e[34mshape\e[0m: ['N', 64, 56, 56] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Add \e[36moutput_name.0\e[0m: resnetv15_stage1__plus1 \e[36mshape\e[0m: (None, 55, 55, 64) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Relu \e[33monnx_op_name\e[0m: resnetv15_stage1_activation1\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage1__plus1 \e[34mshape\e[0m: ['N', 64, 56, 56] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage1_activation1 \e[34mshape\e[0m: ['N', 64, 56, 56] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Relu \e[36moutput_name.0\e[0m: resnetv15_stage1_activation1 \e[36mshape\e[0m: (None, 55, 55, 64) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Conv \e[33monnx_op_name\e[0m: resnetv15_stage2_conv2_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage1_activation1 \e[34mshape\e[0m: ['N', 64, 56, 56] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: 194 \e[34mshape\e[0m: [128, 64, 1, 1] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34minput_name.3\e[0m: 196 \e[34mshape\e[0m: [128] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage2_conv2_fwd \e[34mshape\e[0m: ['N', 128, 28, 28] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Conv \e[36moutput_name.0\e[0m: resnetv15_stage2_conv2_fwd \e[36mshape\e[0m: (None, 28, 28, 128) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Conv \e[33monnx_op_name\e[0m: resnetv15_stage2_conv0_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage1_activation1 \e[34mshape\e[0m: ['N', 64, 56, 56] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: 198 \e[34mshape\e[0m: [128, 64, 3, 3] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34minput_name.3\e[0m: 200 \e[34mshape\e[0m: [128] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage2_conv0_fwd \e[34mshape\e[0m: ['N', 128, 28, 28] \e[34mdtype\e[0m: float32\r\n"
  - delay: 200
    content: "\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Conv \e[36moutput_name.0\e[0m: resnetv15_stage2_conv0_fwd \e[36mshape\e[0m: (None, 28, 28, 128) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Relu \e[33monnx_op_name\e[0m: resnetv15_stage2_relu0_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage2_conv0_fwd \e[34mshape\e[0m: ['N', 128, 28, 28] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage2_relu0_fwd \e[34mshape\e[0m: ['N', 128, 28, 28] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Relu \e[36moutput_name.0\e[0m: resnetv15_stage2_relu0_fwd \e[36mshape\e[0m: (None, 28, 28, 128) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Conv \e[33monnx_op_name\e[0m: resnetv15_stage2_conv1_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage2_relu0_fwd \e[34mshape\e[0m: ['N', 128, 28, 28] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: 202 \e[34mshape\e[0m: [128, 128, 3, 3] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34minput_name.3\e[0m: 204 \e[34mshape\e[0m: [128] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage2_conv1_fwd \e[34mshape\e[0m: ['N', 128, 28, 28] \e[34mdtype\e[0m: float32\r\n"
  - delay: 200
    content: "\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Conv \e[36moutput_name.0\e[0m: resnetv15_stage2_conv1_fwd \e[36mshape\e[0m: (None, 28, 28, 128) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Add \e[33monnx_op_name\e[0m: resnetv15_stage2__plus0\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage2_conv2_fwd \e[34mshape\e[0m: ['N', 128, 28, 28] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: resnetv15_stage2_conv1_fwd \e[34mshape\e[0m: ['N', 128, 28, 28] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage2__plus0 \e[34mshape\e[0m: ['N', 128, 28, 28] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Add \e[36moutput_name.0\e[0m: resnetv15_stage2__plus0 \e[36mshape\e[0m: (None, 28, 28, 128) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Relu \e[33monnx_op_name\e[0m: resnetv15_stage2_activation0\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage2__plus0 \e[34mshape\e[0m: ['N', 128, 28, 28] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage2_activation0 \e[34mshape\e[0m: ['N', 128, 28, 28] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Relu \e[36moutput_name.0\e[0m: resnetv15_stage2_activation0 \e[36mshape\e[0m: (None, 28, 28, 128) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Conv \e[33monnx_op_name\e[0m: resnetv15_stage2_conv3_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage2_activation0 \e[34mshape\e[0m: ['N', 128, 28, 28] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: 206 \e[34mshape\e[0m: [128, 128, 3, 3] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34minput_name.3\e[0m: 208 \e[34mshape\e[0m: [128] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage2_conv3_fwd \e[34mshape\e[0m: ['N', 128, 28, 28] \e[34mdtype\e[0m: float32\r\n"
  - delay: 200
    content: "\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Conv \e[36moutput_name.0\e[0m: resnetv15_stage2_conv3_fwd \e[36mshape\e[0m: (None, 28, 28, 128) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Relu \e[33monnx_op_name\e[0m: resnetv15_stage2_relu1_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage2_conv3_fwd \e[34mshape\e[0m: ['N', 128, 28, 28] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage2_relu1_fwd \e[34mshape\e[0m: ['N', 128, 28, 28] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Relu \e[36moutput_name.0\e[0m: resnetv15_stage2_relu1_fwd \e[36mshape\e[0m: (None, 28, 28, 128) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Conv \e[33monnx_op_name\e[0m: resnetv15_stage2_conv4_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage2_relu1_fwd \e[34mshape\e[0m: ['N', 128, 28, 28] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: 210 \e[34mshape\e[0m: [128, 128, 3, 3] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34minput_name.3\e[0m: 212 \e[34mshape\e[0m: [128] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage2_conv4_fwd \e[34mshape\e[0m: ['N', 128, 28, 28] \e[34mdtype\e[0m: float32\r\n"
  - delay: 200
    content: "\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Conv \e[36moutput_name.0\e[0m: resnetv15_stage2_conv4_fwd \e[36mshape\e[0m: (None, 28, 28, 128) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Add \e[33monnx_op_name\e[0m: resnetv15_stage2__plus1\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage2_activation0 \e[34mshape\e[0m: ['N', 128, 28, 28] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: resnetv15_stage2_conv4_fwd \e[34mshape\e[0m: ['N', 128, 28, 28] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage2__plus1 \e[34mshape\e[0m: ['N', 128, 28, 28] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Add \e[36moutput_name.0\e[0m: resnetv15_stage2__plus1 \e[36mshape\e[0m: (None, 28, 28, 128) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Relu \e[33monnx_op_name\e[0m: resnetv15_stage2_activation1\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage2__plus1 \e[34mshape\e[0m: ['N', 128, 28, 28] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage2_activation1 \e[34mshape\e[0m: ['N', 128, 28, 28] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Relu \e[36moutput_name.0\e[0m: resnetv15_stage2_activation1 \e[36mshape\e[0m: (None, 28, 28, 128) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Conv \e[33monnx_op_name\e[0m: resnetv15_stage3_conv2_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage2_activation1 \e[34mshape\e[0m: ['N', 128, 28, 28] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: 214 \e[34mshape\e[0m: [256, 128, 1, 1] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34minput_name.3\e[0m: 216 \e[34mshape\e[0m: [256] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage3_conv2_fwd \e[34mshape\e[0m: ['N', 256, 14, 14] \e[34mdtype\e[0m: float32\r\n"
  - delay: 200
    content: "\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Conv \e[36moutput_name.0\e[0m: resnetv15_stage3_conv2_fwd \e[36mshape\e[0m: (None, 14, 14, 256) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Conv \e[33monnx_op_name\e[0m: resnetv15_stage3_conv0_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage2_activation1 \e[34mshape\e[0m: ['N', 128, 28, 28] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: 218 \e[34mshape\e[0m: [256, 128, 3, 3] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34minput_name.3\e[0m: 220 \e[34mshape\e[0m: [256] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage3_conv0_fwd \e[34mshape\e[0m: ['N', 256, 14, 14] \e[34mdtype\e[0m: float32\r\n"
  - delay: 200
    content: "\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Conv \e[36moutput_name.0\e[0m: resnetv15_stage3_conv0_fwd \e[36mshape\e[0m: (None, 14, 14, 256) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Relu \e[33monnx_op_name\e[0m: resnetv15_stage3_relu0_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage3_conv0_fwd \e[34mshape\e[0m: ['N', 256, 14, 14] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage3_relu0_fwd \e[34mshape\e[0m: ['N', 256, 14, 14] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Relu \e[36moutput_name.0\e[0m: resnetv15_stage3_relu0_fwd \e[36mshape\e[0m: (None, 14, 14, 256) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Conv \e[33monnx_op_name\e[0m: resnetv15_stage3_conv1_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage3_relu0_fwd \e[34mshape\e[0m: ['N', 256, 14, 14] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: 222 \e[34mshape\e[0m: [256, 256, 3, 3] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34minput_name.3\e[0m: 224 \e[34mshape\e[0m: [256] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage3_conv1_fwd \e[34mshape\e[0m: ['N', 256, 14, 14] \e[34mdtype\e[0m: float32\r\n"
  - delay: 200
    content: "\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Conv \e[36moutput_name.0\e[0m: resnetv15_stage3_conv1_fwd \e[36mshape\e[0m: (None, 14, 14, 256) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Add \e[33monnx_op_name\e[0m: resnetv15_stage3__plus0\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage3_conv2_fwd \e[34mshape\e[0m: ['N', 256, 14, 14] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: resnetv15_stage3_conv1_fwd \e[34mshape\e[0m: ['N', 256, 14, 14] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage3__plus0 \e[34mshape\e[0m: ['N', 256, 14, 14] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Add \e[36moutput_name.0\e[0m: resnetv15_stage3__plus0 \e[36mshape\e[0m: (None, 14, 14, 256) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Relu \e[33monnx_op_name\e[0m: resnetv15_stage3_activation0\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage3__plus0 \e[34mshape\e[0m: ['N', 256, 14, 14] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage3_activation0 \e[34mshape\e[0m: ['N', 256, 14, 14] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Relu \e[36moutput_name.0\e[0m: resnetv15_stage3_activation0 \e[36mshape\e[0m: (None, 14, 14, 256) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Conv \e[33monnx_op_name\e[0m: resnetv15_stage3_conv3_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage3_activation0 \e[34mshape\e[0m: ['N', 256, 14, 14] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: 226 \e[34mshape\e[0m: [256, 256, 3, 3] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34minput_name.3\e[0m: 228 \e[34mshape\e[0m: [256] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage3_conv3_fwd \e[34mshape\e[0m: ['N', 256, 14, 14] \e[34mdtype\e[0m: float32\r\n"
  - delay: 200
    content: "\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Conv \e[36moutput_name.0\e[0m: resnetv15_stage3_conv3_fwd \e[36mshape\e[0m: (None, 14, 14, 256) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Relu \e[33monnx_op_name\e[0m: resnetv15_stage3_relu1_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage3_conv3_fwd \e[34mshape\e[0m: ['N', 256, 14, 14] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage3_relu1_fwd \e[34mshape\e[0m: ['N', 256, 14, 14] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Relu \e[36moutput_name.0\e[0m: resnetv15_stage3_relu1_fwd \e[36mshape\e[0m: (None, 14, 14, 256) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Conv \e[33monnx_op_name\e[0m: resnetv15_stage3_conv4_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage3_relu1_fwd \e[34mshape\e[0m: ['N', 256, 14, 14] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: 230 \e[34mshape\e[0m: [256, 256, 3, 3] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34minput_name.3\e[0m: 232 \e[34mshape\e[0m: [256] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage3_conv4_fwd \e[34mshape\e[0m: ['N', 256, 14, 14] \e[34mdtype\e[0m: float32\r\n"
  - delay: 200
    content: "\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Conv \e[36moutput_name.0\e[0m: resnetv15_stage3_conv4_fwd \e[36mshape\e[0m: (None, 14, 14, 256) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Add \e[33monnx_op_name\e[0m: resnetv15_stage3__plus1\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage3_activation0 \e[34mshape\e[0m: ['N', 256, 14, 14] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: resnetv15_stage3_conv4_fwd \e[34mshape\e[0m: ['N', 256, 14, 14] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage3__plus1 \e[34mshape\e[0m: ['N', 256, 14, 14] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Add \e[36moutput_name.0\e[0m: resnetv15_stage3__plus1 \e[36mshape\e[0m: (None, 14, 14, 256) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Relu \e[33monnx_op_name\e[0m: resnetv15_stage3_activation1\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage3__plus1 \e[34mshape\e[0m: ['N', 256, 14, 14] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage3_activation1 \e[34mshape\e[0m: ['N', 256, 14, 14] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Relu \e[36moutput_name.0\e[0m: resnetv15_stage3_activation1 \e[36mshape\e[0m: (None, 14, 14, 256) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Conv \e[33monnx_op_name\e[0m: resnetv15_stage4_conv2_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage3_activation1 \e[34mshape\e[0m: ['N', 256, 14, 14] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: 234 \e[34mshape\e[0m: [512, 256, 1, 1] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34minput_name.3\e[0m: 236 \e[34mshape\e[0m: [512] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage4_conv2_fwd \e[34mshape\e[0m: ['N', 512, 7, 7] \e[34mdtype\e[0m: float32\r\n"
  - delay: 200
    content: "\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Conv \e[36moutput_name.0\e[0m: resnetv15_stage4_conv2_fwd \e[36mshape\e[0m: (None, 7, 7, 512) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Conv \e[33monnx_op_name\e[0m: resnetv15_stage4_conv0_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage3_activation1 \e[34mshape\e[0m: ['N', 256, 14, 14] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: 238 \e[34mshape\e[0m: [512, 256, 3, 3] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34minput_name.3\e[0m: 240 \e[34mshape\e[0m: [512] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage4_conv0_fwd \e[34mshape\e[0m: ['N', 512, 7, 7] \e[34mdtype\e[0m: float32\r\n"
  - delay: 200
    content: "\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Conv \e[36moutput_name.0\e[0m: resnetv15_stage4_conv0_fwd \e[36mshape\e[0m: (None, 7, 7, 512) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Relu \e[33monnx_op_name\e[0m: resnetv15_stage4_relu0_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage4_conv0_fwd \e[34mshape\e[0m: ['N', 512, 7, 7] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage4_relu0_fwd \e[34mshape\e[0m: ['N', 512, 7, 7] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Relu \e[36moutput_name.0\e[0m: resnetv15_stage4_relu0_fwd \e[36mshape\e[0m: (None, 7, 7, 512) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Conv \e[33monnx_op_name\e[0m: resnetv15_stage4_conv1_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage4_relu0_fwd \e[34mshape\e[0m: ['N', 512, 7, 7] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: 242 \e[34mshape\e[0m: [512, 512, 3, 3] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34minput_name.3\e[0m: 244 \e[34mshape\e[0m: [512] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage4_conv1_fwd \e[34mshape\e[0m: ['N', 512, 7, 7] \e[34mdtype\e[0m: float32\r\n"
  - delay: 200
    content: "\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Conv \e[36moutput_name.0\e[0m: resnetv15_stage4_conv1_fwd \e[36mshape\e[0m: (None, 7, 7, 512) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Add \e[33monnx_op_name\e[0m: resnetv15_stage4__plus0\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage4_conv2_fwd \e[34mshape\e[0m: ['N', 512, 7, 7] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: resnetv15_stage4_conv1_fwd \e[34mshape\e[0m: ['N', 512, 7, 7] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage4__plus0 \e[34mshape\e[0m: ['N', 512, 7, 7] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Add \e[36moutput_name.0\e[0m: resnetv15_stage4__plus0 \e[36mshape\e[0m: (None, 7, 7, 512) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Relu \e[33monnx_op_name\e[0m: resnetv15_stage4_activation0\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage4__plus0 \e[34mshape\e[0m: ['N', 512, 7, 7] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage4_activation0 \e[34mshape\e[0m: ['N', 512, 7, 7] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Relu \e[36moutput_name.0\e[0m: resnetv15_stage4_activation0 \e[36mshape\e[0m: (None, 7, 7, 512) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Conv \e[33monnx_op_name\e[0m: resnetv15_stage4_conv3_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage4_activation0 \e[34mshape\e[0m: ['N', 512, 7, 7] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: 246 \e[34mshape\e[0m: [512, 512, 3, 3] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34minput_name.3\e[0m: 248 \e[34mshape\e[0m: [512] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage4_conv3_fwd \e[34mshape\e[0m: ['N', 512, 7, 7] \e[34mdtype\e[0m: float32\r\n"
  - delay: 200
    content: "\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Conv \e[36moutput_name.0\e[0m: resnetv15_stage4_conv3_fwd \e[36mshape\e[0m: (None, 7, 7, 512) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Relu \e[33monnx_op_name\e[0m: resnetv15_stage4_relu1_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage4_conv3_fwd \e[34mshape\e[0m: ['N', 512, 7, 7] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage4_relu1_fwd \e[34mshape\e[0m: ['N', 512, 7, 7] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Relu \e[36moutput_name.0\e[0m: resnetv15_stage4_relu1_fwd \e[36mshape\e[0m: (None, 7, 7, 512) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Conv \e[33monnx_op_name\e[0m: resnetv15_stage4_conv4_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage4_relu1_fwd \e[34mshape\e[0m: ['N', 512, 7, 7] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: 250 \e[34mshape\e[0m: [512, 512, 3, 3] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34minput_name.3\e[0m: 252 \e[34mshape\e[0m: [512] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage4_conv4_fwd \e[34mshape\e[0m: ['N', 512, 7, 7] \e[34mdtype\e[0m: float32\r\n"
  - delay: 200
    content: "\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Conv \e[36moutput_name.0\e[0m: resnetv15_stage4_conv4_fwd \e[36mshape\e[0m: (None, 7, 7, 512) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Add \e[33monnx_op_name\e[0m: resnetv15_stage4__plus1\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage4_activation0 \e[34mshape\e[0m: ['N', 512, 7, 7] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: resnetv15_stage4_conv4_fwd \e[34mshape\e[0m: ['N', 512, 7, 7] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage4__plus1 \e[34mshape\e[0m: ['N', 512, 7, 7] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Add \e[36moutput_name.0\e[0m: resnetv15_stage4__plus1 \e[36mshape\e[0m: (None, 7, 7, 512) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Relu \e[33monnx_op_name\e[0m: resnetv15_stage4_activation1\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage4__plus1 \e[34mshape\e[0m: ['N', 512, 7, 7] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_stage4_activation1 \e[34mshape\e[0m: ['N', 512, 7, 7] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Relu \e[36moutput_name.0\e[0m: resnetv15_stage4_activation1 \e[36mshape\e[0m: (None, 7, 7, 512) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: GlobalAveragePool \e[33monnx_op_name\e[0m: resnetv15_pool1_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_stage4_activation1 \e[34mshape\e[0m: ['N', 512, 7, 7] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_pool1_fwd \e[34mshape\e[0m: ['N', 512, 1, 1] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: GlobalAveragePool \e[36moutput_name.0\e[0m: resnetv15_pool1_fwd \e[36mshape\e[0m: (None, 1, 1, 512) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Flatten \e[33monnx_op_name\e[0m: flatten_170\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: resnetv15_pool1_fwd \e[34mshape\e[0m: ['N', 512, 1, 1] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: flatten_170 \e[34mshape\e[0m: ['N', 512] \e[34mdtype\e[0m: float32\r\n"
  - delay: 200
    content: "\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Flatten \e[36moutput_name.0\e[0m: flatten_170 \e[36mshape\e[0m: (None, 512) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\e[32mINFO:\e[0m \e[33monnx_op_type\e[0m: Gemm \e[33monnx_op_name\e[0m: resnetv15_dense0_fwd\r\n\e[32mINFO:\e[0m \e[34minput_name.1\e[0m: flatten_170 \e[34mshape\e[0m: ['N', 512] \e[34mdtype\e[0m: float32\r\n\e[32mINFO:\e[0m \e[34minput_name.2\e[0m: resnetv15_dense0_weight \e[34mshape\e[0m: [1000, 512] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34minput_name.3\e[0m: resnetv15_dense0_bias \e[34mshape\e[0m: [1000] \e[34mdtype\e[0m: <class 'numpy.float32'>\r\n\e[32mINFO:\e[0m \e[34moutput_name.1\e[0m: resnetv15_dense0_fwd \e[34mshape\e[0m: ['N', 1000] \e[34mdtype\e[0m: float32\r\n"
  - delay: 200
    content: "\e[32mINFO:\e[0m \e[36mtf_op_type\e[0m: Gemm \e[36moutput_name.0\e[0m: resnetv15_dense0_fwd \e[36mshape\e[0m: (None, 1000) \e[36mdtype\e[0m: <dtype: 'float32'>\r\n\r\n"
  - delay: 3000
    content: "Model: \"model\"\r\n____________________________________________________________________________________________________________________________________________\r\n Layer (type)                                 Output Shape                   Param #         Connected to                                   \r\n============================================================================================================================================\r\n data (InputLayer)                            [(None, 224, 224, 3)]          0               []                                             \r\n                                                                                                                                            \r\n tf.compat.v1.pad (TFOpLambda)                (None, 230, 230, 3)            0               ['data[0][0]']                                 \r\n                                                                                                                                            \r\n tf.nn.convolution (TFOpLambda)               (None, 112, 112, 64)           0               ['tf.compat.v1.pad[0][0]']                     \r\n                                                                                                                                            \r\n tf.math.add (TFOpLambda)                     (None, 112, 112, 64)           0               ['tf.nn.convolution[0][0]']                    \r\n                                                                                                                                            \r\n tf.nn.relu (TFOpLambda)                      (None, 112, 112, 64)           0               ['tf.math.add[0][0]']                          \r\n                                                                                                                                            \r\n tf.nn.max_pool2d (TFOpLambda)                (None, 55, 55, 64)             0               ['tf.nn.relu[0][0]']                           \r\n                                                                                                                                            \r\n tf.compat.v1.pad_2 (TFOpLambda)              (None, 57, 57, 64)             0               ['tf.nn.max_pool2d[0][0]']                     \r\n                                                                                                                                            \r\n tf.nn.convolution_1 (TFOpLambda)             (None, 55, 55, 64)             0               ['tf.compat.v1.pad_2[0][0]']                   \r\n                                                                                                                                            \r\n tf.math.add_1 (TFOpLambda)                   (None, 55, 55, 64)             0               ['tf.nn.convolution_1[0][0]']                  \r\n                                                                                                                                            \r\n tf.nn.relu_1 (TFOpLambda)                    (None, 55, 55, 64)             0               ['tf.math.add_1[0][0]']                        \r\n                                                                                                                                            \r\n tf.compat.v1.pad_3 (TFOpLambda)              (None, 57, 57, 64)             0               ['tf.nn.relu_1[0][0]']                         \r\n                                                                                                                                            \r\n tf.nn.convolution_2 (TFOpLambda)             (None, 55, 55, 64)             0               ['tf.compat.v1.pad_3[0][0]']                   \r\n                                                                                                                                            \r\n tf.math.add_2 (TFOpLambda)                   (None, 55, 55, 64)             0               ['tf.nn.convolution_2[0][0]']                  \r\n                                                                                                                                            \r\n tf.math.add_3 (TFOpLambda)                   (None, 55, 55, 64)             0               ['tf.nn.max_pool2d[0][0]',                     \r\n                                                                                              'tf.math.add_2[0][0]']                        \r\n                                                                                                                                            \r\n tf.nn.relu_2 (TFOpLambda)                    (None, 55, 55, 64)             0               ['tf.math.add_3[0][0]']                        \r\n                                                                                                                                            \r\n tf.compat.v1.pad_4 (TFOpLambda)              (None, 57, 57, 64)             0               ['tf.nn.relu_2[0][0]']                         \r\n                                                                                                                                            \r\n tf.nn.convolution_3 (TFOpLambda)             (None, 55, 55, 64)             0               ['tf.compat.v1.pad_4[0][0]']                   \r\n                                                                                                                                            \r\n tf.math.add_4 (TFOpLambda)                   (None, 55, 55, 64)             0               ['tf.nn.convolution_3[0][0]']                  \r\n                                                                                                                                            \r\n tf.nn.relu_3 (TFOpLambda)                    (None, 55, 55, 64)             0               ['tf.math.add_4[0][0]']                        \r\n                                                                                                                                            \r\n tf.compat.v1.pad_5 (TFOpLambda)              (None, 57, 57, 64)             0               ['tf.nn.relu_3[0][0]']                         \r\n                                                                                                                                            \r\n tf.nn.convolution_4 (TFOpLambda)             (None, 55, 55, 64)             0               ['tf.compat.v1.pad_5[0][0]']                   \r\n                                                                                                                                            \r\n tf.math.add_5 (TFOpLambda)                   (None, 55, 55, 64)             0               ['tf.nn.convolution_4[0][0]']                  \r\n                                                                                                                                            \r\n tf.math.add_6 (TFOpLambda)                   (None, 55, 55, 64)             0               ['tf.nn.relu_2[0][0]',                         \r\n                                                                                              'tf.math.add_5[0][0]']                        \r\n                                                                                                                                            \r\n tf.nn.relu_4 (TFOpLambda)                    (None, 55, 55, 64)             0               ['tf.math.add_6[0][0]']                        \r\n                                                                                                                                            \r\n tf.compat.v1.pad_6 (TFOpLambda)              (None, 57, 57, 64)             0               ['tf.nn.relu_4[0][0]']                         \r\n                                                                                                                                            \r\n tf.nn.convolution_6 (TFOpLambda)             (None, 28, 28, 128)            0               ['tf.compat.v1.pad_6[0][0]']                   \r\n                                                                                                                                            \r\n tf.math.add_8 (TFOpLambda)                   (None, 28, 28, 128)            0               ['tf.nn.convolution_6[0][0]']                  \r\n                                                                                                                                            \r\n tf.nn.relu_5 (TFOpLambda)                    (None, 28, 28, 128)            0               ['tf.math.add_8[0][0]']                        \r\n                                                                                                                                            \r\n tf.compat.v1.pad_7 (TFOpLambda)              (None, 30, 30, 128)            0               ['tf.nn.relu_5[0][0]']                         \r\n                                                                                                                                            \r\n tf.nn.convolution_5 (TFOpLambda)             (None, 28, 28, 128)            0               ['tf.nn.relu_4[0][0]']                         \r\n                                                                                                                                            \r\n tf.nn.convolution_7 (TFOpLambda)             (None, 28, 28, 128)            0               ['tf.compat.v1.pad_7[0][0]']                   \r\n                                                                                                                                            \r\n tf.math.add_7 (TFOpLambda)                   (None, 28, 28, 128)            0               ['tf.nn.convolution_5[0][0]']                  \r\n                                                                                                                                            \r\n tf.math.add_9 (TFOpLambda)                   (None, 28, 28, 128)            0               ['tf.nn.convolution_7[0][0]']                  \r\n                                                                                                                                            \r\n tf.math.add_10 (TFOpLambda)                  (None, 28, 28, 128)            0               ['tf.math.add_7[0][0]',                        \r\n                                                                                              'tf.math.add_9[0][0]']                        \r\n                                                                                                                                            \r\n tf.nn.relu_6 (TFOpLambda)                    (None, 28, 28, 128)            0               ['tf.math.add_10[0][0]']                       \r\n                                                                                                                                            \r\n tf.compat.v1.pad_8 (TFOpLambda)              (None, 30, 30, 128)            0               ['tf.nn.relu_6[0][0]']                         \r\n                                                                                                                                            \r\n tf.nn.convolution_8 (TFOpLambda)             (None, 28, 28, 128)            0               ['tf.compat.v1.pad_8[0][0]']                   \r\n                                                                                                                                            \r\n tf.math.add_11 (TFOpLambda)                  (None, 28, 28, 128)            0               ['tf.nn.convolution_8[0][0]']                  \r\n                                                                                                                                            \r\n tf.nn.relu_7 (TFOpLambda)                    (None, 28, 28, 128)            0               ['tf.math.add_11[0][0]']                       \r\n                                                                                                                                            \r\n tf.compat.v1.pad_9 (TFOpLambda)              (None, 30, 30, 128)            0               ['tf.nn.relu_7[0][0]']                         \r\n                                                                                                                                            \r\n tf.nn.convolution_9 (TFOpLambda)             (None, 28, 28, 128)            0               ['tf.compat.v1.pad_9[0][0]']                   \r\n                                                                                                                                            \r\n tf.math.add_12 (TFOpLambda)                  (None, 28, 28, 128)            0               ['tf.nn.convolution_9[0][0]']                  \r\n                                                                                                                                            \r\n tf.math.add_13 (TFOpLambda)                  (None, 28, 28, 128)            0               ['tf.nn.relu_6[0][0]',                         \r\n                                                                                              'tf.math.add_12[0][0]']                       \r\n                                                                                                                                            \r\n tf.nn.relu_8 (TFOpLambda)                    (None, 28, 28, 128)            0               ['tf.math.add_13[0][0]']                       \r\n                                                                                                                                            \r\n tf.compat.v1.pad_10 (TFOpLambda)             (None, 30, 30, 128)            0               ['tf.nn.relu_8[0][0]']                         \r\n                                                                                                                                            \r\n tf.nn.convolution_11 (TFOpLambda)            (None, 14, 14, 256)            0               ['tf.compat.v1.pad_10[0][0]']                  \r\n                                                                                                                                            \r\n tf.math.add_15 (TFOpLambda)                  (None, 14, 14, 256)            0               ['tf.nn.convolution_11[0][0]']                 \r\n                                                                                                                                            \r\n tf.nn.relu_9 (TFOpLambda)                    (None, 14, 14, 256)            0               ['tf.math.add_15[0][0]']                       \r\n                                                                                                                                            \r\n tf.compat.v1.pad_11 (TFOpLambda)             (None, 16, 16, 256)            0               ['tf.nn.relu_9[0][0]']                         \r\n                                                                                                                                            \r\n tf.nn.convolution_10 (TFOpLambda)            (None, 14, 14, 256)            0               ['tf.nn.relu_8[0][0]']                         \r\n                                                                                                                                            \r\n tf.nn.convolution_12 (TFOpLambda)            (None, 14, 14, 256)            0               ['tf.compat.v1.pad_11[0][0]']                  \r\n                                                                                                                                            \r\n tf.math.add_14 (TFOpLambda)                  (None, 14, 14, 256)            0               ['tf.nn.convolution_10[0][0]']                 \r\n                                                                                                                                            \r\n tf.math.add_16 (TFOpLambda)                  (None, 14, 14, 256)            0               ['tf.nn.convolution_12[0][0]']                 \r\n                                                                                                                                            \r\n tf.math.add_17 (TFOpLambda)                  (None, 14, 14, 256)            0               ['tf.math.add_14[0][0]',                       \r\n                                                                                              'tf.math.add_16[0][0]']                       \r\n                                                                                                                                            \r\n tf.nn.relu_10 (TFOpLambda)                   (None, 14, 14, 256)            0               ['tf.math.add_17[0][0]']                       \r\n                                                                                                                                            \r\n tf.compat.v1.pad_12 (TFOpLambda)             (None, 16, 16, 256)            0               ['tf.nn.relu_10[0][0]']                        \r\n                                                                                                                                            \r\n tf.nn.convolution_13 (TFOpLambda)            (None, 14, 14, 256)            0               ['tf.compat.v1.pad_12[0][0]']                  \r\n                                                                                                                                            \r\n tf.math.add_18 (TFOpLambda)                  (None, 14, 14, 256)            0               ['tf.nn.convolution_13[0][0]']                 \r\n                                                                                                                                            \r\n tf.nn.relu_11 (TFOpLambda)                   (None, 14, 14, 256)            0               ['tf.math.add_18[0][0]']                       \r\n                                                                                                                                            \r\n tf.compat.v1.pad_13 (TFOpLambda)             (None, 16, 16, 256)            0               ['tf.nn.relu_11[0][0]']                        \r\n                                                                                                                                            \r\n tf.nn.convolution_14 (TFOpLambda)            (None, 14, 14, 256)            0               ['tf.compat.v1.pad_13[0][0]']                  \r\n                                                                                                                                            \r\n tf.math.add_19 (TFOpLambda)                  (None, 14, 14, 256)            0               ['tf.nn.convolution_14[0][0]']                 \r\n                                                                                                                                            \r\n tf.math.add_20 (TFOpLambda)                  (None, 14, 14, 256)            0               ['tf.nn.relu_10[0][0]',                        \r\n                                                                                              'tf.math.add_19[0][0]']                       \r\n                                                                                                                                            \r\n tf.nn.relu_12 (TFOpLambda)                   (None, 14, 14, 256)            0               ['tf.math.add_20[0][0]']                       \r\n                                                                                                                                            \r\n tf.compat.v1.pad_14 (TFOpLambda)             (None, 16, 16, 256)            0               ['tf.nn.relu_12[0][0]']                        \r\n                                                                                                                                            \r\n tf.nn.convolution_16 (TFOpLambda)            (None, 7, 7, 512)              0               ['tf.compat.v1.pad_14[0][0]']                  \r\n                                                                                                                                            \r\n tf.math.add_22 (TFOpLambda)                  (None, 7, 7, 512)              0               ['tf.nn.convolution_16[0][0]']                 \r\n                                                                                                                                            \r\n tf.nn.relu_13 (TFOpLambda)                   (None, 7, 7, 512)              0               ['tf.math.add_22[0][0]']                       \r\n                                                                                                                                            \r\n tf.compat.v1.pad_15 (TFOpLambda)             (None, 9, 9, 512)              0               ['tf.nn.relu_13[0][0]']                        \r\n                                                                                                                                            \r\n tf.nn.convolution_15 (TFOpLambda)            (None, 7, 7, 512)              0               ['tf.nn.relu_12[0][0]']                        \r\n                                                                                                                                            \r\n tf.nn.convolution_17 (TFOpLambda)            (None, 7, 7, 512)              0               ['tf.compat.v1.pad_15[0][0]']                  \r\n                                                                                                                                            \r\n tf.math.add_21 (TFOpLambda)                  (None, 7, 7, 512)              0               ['tf.nn.convolution_15[0][0]']                 \r\n                                                                                                                                            \r\n tf.math.add_23 (TFOpLambda)                  (None, 7, 7, 512)              0               ['tf.nn.convolution_17[0][0]']                 \r\n                                                                                                                                            \r\n tf.math.add_24 (TFOpLambda)                  (None, 7, 7, 512)              0               ['tf.math.add_21[0][0]',                       \r\n                                                                                              'tf.math.add_23[0][0]']                       \r\n                                                                                                                                            \r\n tf.nn.relu_14 (TFOpLambda)                   (None, 7, 7, 512)              0               ['tf.math.add_24[0][0]']                       \r\n                                                                                                                                            \r\n tf.compat.v1.pad_16 (TFOpLambda)             (None, 9, 9, 512)              0               ['tf.nn.relu_14[0][0]']                        \r\n                                                                                                                                            \r\n tf.nn.convolution_18 (TFOpLambda)            (None, 7, 7, 512)              0               ['tf.compat.v1.pad_16[0][0]']                  \r\n                                                                                                                                            \r\n tf.math.add_25 (TFOpLambda)                  (None, 7, 7, 512)              0               ['tf.nn.convolution_18[0][0]']                 \r\n                                                                                                                                            \r\n tf.nn.relu_15 (TFOpLambda)                   (None, 7, 7, 512)              0               ['tf.math.add_25[0][0]']                       \r\n                                                                                                                                            \r\n tf.compat.v1.pad_17 (TFOpLambda)             (None, 9, 9, 512)              0               ['tf.nn.relu_15[0][0]']                        \r\n                                                                                                                                            \r\n tf.nn.convolution_19 (TFOpLambda)            (None, 7, 7, 512)              0               ['tf.compat.v1.pad_17[0][0]']                  \r\n                                                                                                                                            \r\n tf.math.add_26 (TFOpLambda)                  (None, 7, 7, 512)              0               ['tf.nn.convolution_19[0][0]']                 \r\n                                                                                                                                            \r\n tf.math.add_27 (TFOpLambda)                  (None, 7, 7, 512)              0               ['tf.nn.relu_14[0][0]',                        \r\n                                                                                              'tf.math.add_26[0][0]']                       \r\n                                                                                                                                            \r\n tf.nn.relu_16 (TFOpLambda)                   (None, 7, 7, 512)              0               ['tf.math.add_27[0][0]']                       \r\n                                                                                                                                            \r\n tf.math.reduce_mean (TFOpLambda)             (None, 1, 1, 512)              0               ['tf.nn.relu_16[0][0]']                        \r\n                                                                                                                                            \r\n tf.compat.v1.shape_1 (TFOpLambda)            (4,)                           0               ['tf.math.reduce_mean[0][0]']                  \r\n                                                                                                                                            \r\n tf.compat.v1.size (TFOpLambda)               ()                             0               ['tf.compat.v1.shape_1[0][0]']                 \r\n                                                                                                                                            \r\n tf.__operators__.getitem_1 (SlicingOpLambda)  (3,)                          0               ['tf.compat.v1.shape_1[0][0]']                 \r\n                                                                                                                                            \r\n tf.__operators__.getitem_2 (SlicingOpLambda)  (1,)                          0               ['tf.compat.v1.shape_1[0][0]',                 \r\n                                                                                              'tf.compat.v1.size[0][0]']                    \r\n                                                                                                                                            \r\n tf.math.reduce_prod (TFOpLambda)             ()                             0               ['tf.__operators__.getitem_1[0][0]']           \r\n                                                                                                                                            \r\n tf.math.reduce_prod_1 (TFOpLambda)           ()                             0               ['tf.__operators__.getitem_2[0][0]']           \r\n                                                                                                                                            \r\n tf.reshape (TFOpLambda)                      (None, 512)                    0               ['tf.math.reduce_mean[0][0]',                  \r\n                                                                                              'tf.math.reduce_prod[0][0]',                  \r\n                                                                                              'tf.math.reduce_prod_1[0][0]']                \r\n                                                                                                                                            \r\n flatten (Flatten)                            (None, 512)                    0               ['tf.reshape[0][0]']                           \r\n                                                                                                                                            \r\n tf.cast (TFOpLambda)                         (None, 512)                    0               ['flatten[0][0]']                              \r\n                                                                                                                                            \r\n tf.linalg.matmul (TFOpLambda)                (None, 1000)                   0               ['tf.cast[0][0]']                              \r\n                                                                                                                                            \r\n tf.math.multiply (TFOpLambda)                (None, 1000)                   0               ['tf.linalg.matmul[0][0]']                     \r\n                                                                                                                                            \r\n tf.__operators__.add (TFOpLambda)            (None, 1000)                   0               ['tf.math.multiply[0][0]']                     \r\n                                                                                                                                            \r\n tf.cast_1 (TFOpLambda)                       (None, 1000)                   0               ['tf.__operators__.add[0][0]']                 \r\n                                                                                                                                            \r\n============================================================================================================================================\r\nTotal params: 0\r\nTrainable params: 0\r\nNon-trainable params: 0\r\n____________________________________________________________________________________________________________________________________________\r\n\r\n"
  - delay: 200
    content: "\e[07msaved_model output started\e[0m ==========================================================\r\n"
  - delay: 1500
    content: "\e]0;xxxxxxx@xxxxxxx:~/git/onnx2tf\e\\\e]7;file://xxxxxxx/home/xxxxxxx/git/onnx2tf\e\\\e]0;xxxxxxx@xxxxxxx: ~/git/onnx2tf\a\e[01;32m\e[01;34m~/git/onnx2tf\e[00m$ "
  - delay: 2000
    content: l
  - delay: 150
    content: s
  - delay: 150
    content: ' '
  - delay: 150
    content: '-'
  - delay: 150
    content: l
  - delay: 150
    content: ' '
  - delay: 150
    content: s
  - delay: 150
    content: a
  - delay: 150
    content: v
  - delay: 150
    content: e
  - delay: 150
    content: d_model/
  - delay: 2002
    content: "\r\n"
  - delay: 6
    content: "total 91356\r\ndrwxr-xr-x 2 xxxxxxx xxxxxxx     4096  9月 28 21:24 \e[0m\e[01;34massets\e[0m\r\n-rw-rw-r-- 1 xxxxxxx xxxxxxx 46757396 10月  3 11:37 model_float32.tflite\r\n-rw-rw-r-- 1 xxxxxxx xxxxxxx 46774983 10月  3 11:37 saved_model.pb\r\ndrwxr-xr-x 2 xxxxxxx xxxxxxx     4096 10月  3 11:37 \e[01;34mvariables\e[0m\r\n\e]0;xxxxxxx@xxxxxxx:~/git/onnx2tf\e\\\e]7;file://xxxxxxx/home/xxxxxxx/git/onnx2tf\e\\\e]0;xxxxxxx@xxxxxxx: ~/git/onnx2tf\a\e[01;32m\e[01;34m~/git/onnx2tf\e[00m$ "
  - delay: 6000
    content: "logout\r\n"
